---
title: "WHO, Covid-19 situation report"
author: "Mitsuo Shiota"
date: "2020/3/7"
output: 
  github_document:
    toc: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Updated: `r Sys.Date()`

## Summary

<https://mitsuoxv.shinyapps.io/covid/>

Coronavirus is affecting the world economy. Uncertaintiy is very high. I searched around and found some informative sites, like [Coronavirus Situation Dashboard](https://who.maps.arcgis.com/apps/opsdashboard/index.html#/c88e37cfc43b4ed3baf977d77e4a0667) and [Coronavirus Update by worldometer](https://www.worldometers.info/coronavirus/). But they fail to offer time-series data of the newly confirmed cases by each area, in which I am most interested. If the average number of infections one infected person inflict is even slightly more than one, infections grow exponentially. If less than one, the newly confirmed cases begin to decrease, and the virus will be contained eventually in that area.

WHO offers those numbers in [the situation reports](https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/), which are unfortunately pdf files.

So I scratched numbers from pdf files, scratched my head learning regular expressions, and made the shiny app above. I would like to update frequently, but I am not sure. The ugly codes I wrote are in R directory. Data in Table 1 (In China) and Table 2 (World including China) in the situation reports are in table1.csv, table2.csv and tables.rdata in data directory.

Note that the confirmed cases are not the actual cases, due to delays from infection to symptoms, limited testing capacity, and so on, as [Nate Silver tells us](https://fivethirtyeight.com/features/coronavirus-case-counts-are-meaningless/).

I later found [Johns Hopkins University, Coronavirus Resource Center](https://coronavirus.jhu.edu/) and [Financial Times, Coronavirus tracked](https://www.ft.com/content/a26fbf7e-48f8-11ea-aeb3-955839e06441) are very informative, and that they provide some time-series charts of the newly confirmed cases.

I added the United States page to [my Shiny App](https://mitsuoxv.shinyapps.io/covid/) on May 25, 2020. I use data from [USAFacts page](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/).

```{r library, include=FALSE}
library(tidyverse)
library(rvest)
```

## Load

Here, I load Table 1 and Table 2, which I managed to scratch from WHO situation reports. Beware Table 1 (in_china) includes total, but Table 2 (world) does not include subtotal or total, as I cut them.

```{r load}
# load data
load("data/tables.rdata")
```

## Newly confirmed cases by region

I watch newly confirmed cases. China is suceeding to contain the coronavirus, but areas outside China now face the challenge.

```{r chart, echo=FALSE}
table2 %>% 
  left_join(area_cat, by = "area") %>% 
  group_by(publish_date, cat) %>% 
  summarize(new_conf = sum(new_conf, na.rm = TRUE)) %>% 
  ggplot(aes(publish_date, new_conf,
             color = fct_reorder2(cat, publish_date, new_conf))) +
  geom_hline(yintercept = 0, color = "white", size = 2) +
  geom_line(size = 1) +
  labs(
    title = "Confirmed cases (new)",
    x = "published date",
    caption = str_c("Latest: ", max(table2$publish_date)),
    color = NULL
  ) +
  ylab(NULL) +
  theme(
        plot.title = element_text(size = rel(2)))

```

## Fastest spreading areas

Among areas with more than 10 million population, highest "speed_since_100",  which is average number of newly confirmed cases per day since cumulative cases became more than 100, are:

```{r per_capita, echo=FALSE}
cc_html <- read_html("https://countrycode.org/")

cc_df <- cc_html %>% 
  html_nodes("table") %>% 
  .[[1]] %>% 
  html_table()

cc_df$POPULATION <- as.numeric(str_remove_all(cc_df$POPULATION, ","))

areas_10m <- table2 %>% 
  left_join(cc_df, by = c("area" = "COUNTRY")) %>% 
  filter(POPULATION >= 10000000)

areas_10m %>% 
  group_by(area) %>% 
  arrange(publish_date) %>% 
  filter(cum_conf > 100) %>% 
  mutate(
    days_since_100 = row_number(publish_date),
    speed_since_100 = (cum_conf - min(cum_conf)) / days_since_100
    ) %>% 
  ungroup() %>% 
  filter(publish_date == max(publish_date)) %>% 
  arrange(desc(speed_since_100)) %>% 
  select(area, speed_since_100, cum_conf, days_since_100) %>% 
  head(20)
```

Above calculation might be unfair to populous areas. Below "per_capita_cum_conf" is cumulative cases per 1 million population. Highest "speed_std_since_100", which is per day growth of cumulative cases per 1 million population since cumulative cases became more than 100, are:

```{r standardized, echo=FALSE}
areas_10m %>% 
  group_by(area) %>% 
  arrange(publish_date) %>% 
  filter(cum_conf > 100) %>% 
  mutate(
    days_since_100 = row_number(publish_date),
    per_capita_cum_conf = cum_conf * 1000000 / POPULATION,
    speed_std_since_100 = (cum_conf - min(cum_conf)) * 1000000 / POPULATION / days_since_100
    ) %>% 
  ungroup() %>% 
  filter(publish_date == max(publish_date)) %>% 
  arrange(desc(speed_std_since_100)) %>% 
  select(area, speed_std_since_100, per_capita_cum_conf, days_since_100) %>% 
  head(20)
```


## Highest fatality rate areas

Among areas with more than 10 million population and more than 10 cumulative deaths, highest "fatality_rate", which is cumulative deaths per 100 cumulative confirmed cases, are:

```{r fatality_rates, echo=FALSE}
areas_10m %>% 
  filter(
    cum_deaths > 10,
    publish_date == max(publish_date)
    ) %>% 
  mutate(fatality_rate = cum_deaths * 100 / cum_conf) %>% 
  arrange(desc(fatality_rate)) %>% 
  select(area, fatality_rate, cum_deaths, cum_conf) %>% 
  head(20)
```

## Highest deaths per population areas

Among areas with more than 10 million population, highest "deaths_per_1m", which is cumulative deaths per 1 million population, are:

```{r deaths_per_population, echo=FALSE}
areas_10m %>% 
  filter(
    publish_date == max(publish_date)
    ) %>% 
  mutate(
    pop_mil = POPULATION / 1000000,
    deaths_per_1m = cum_deaths / pop_mil
    ) %>% 
  arrange(desc(deaths_per_1m)) %>% 
  select(area, deaths_per_1m, cum_deaths, pop_mil) %>% 
  head(20)
```

## U.S. deaths (new) by red or blue states

I am worrying that too vigorous "reopen economy" movements in the red states in the United States may cause the second wave. I separate red or blue by state governors (in case of DC, a mayor), according to [List of United States governors](https://en.wikipedia.org/wiki/List_of_United_States_governors).

```{r chart_usa, echo=FALSE, warning=FALSE}
# states by party
gov_html <- read_html("https://en.wikipedia.org/wiki/List_of_United_States_governors")

gov_df <- gov_html %>% 
  html_nodes("table") %>% 
  .[[1]] %>% 
  html_table(fill = TRUE)

gov_df <- gov_df[-1, c(1, 5)]

names(gov_df) <- c("state_name", "party")

gov_df <- gov_df %>% 
  mutate(party = str_sub(party, 1L, 10L))

dc_df <- gov_html %>% 
  html_nodes("table") %>% 
  .[[3]] %>% 
  html_table(fill = TRUE)

dc_df <- dc_df[-1, c(1, 5)]

names(dc_df) <- c("state_name", "party")

gov_dc_df <- bind_rows(gov_df, dc_df)

# chart
data_usa %>% 
  left_join(gov_dc_df, by = "state_name") %>% 
  group_by(publish_date, party) %>% 
  summarize(new_deaths = sum(new_deaths)) %>% 
  ggplot(aes(publish_date, new_deaths, color = party)) +
  geom_line(size = 1) +
  scale_color_manual(values = c("blue", "red")) +
  labs(
    title = "Deaths (new) in the United States",
    x = "published date",
    caption = str_c("Latest: ", max(data_usa$publish_date)),
    color = NULL
  ) +
  ylab(NULL) +
  theme(
    plot.title = element_text(size = rel(2)))
```


EOL

